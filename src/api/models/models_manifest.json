{
  "feature-extraction": [
    {
      "id": "BAAI/bge-large-en-v1.5",
      "name": "bge-large-en-v1.5",
      "team": "BAAI",
      "task": "feature-extraction",
      "size_mb": 1340,
      "parameters_m": 335,
      "gpu_memory_mb": 2048,
      "link": "https://huggingface.co/BAAI/bge-large-en-v1.5"
    },
    {
      "id": "Alibaba-NLP/gte-large-en-v1.5",
      "name": "gte-large-en-v1.5",
      "team": "Alibaba-NLP",
      "task": "feature-extraction",
      "size_mb": 1340,
      "parameters_m": 335,
      "gpu_memory_mb": 2048,
      "link": "https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5"
    },
    {
      "id": "intfloat/e5-large-v2",
      "name": "E5-large-v2",
      "team": "intfloat",
      "task": "feature-extraction",
      "size_mb": 1340,
      "parameters_m": 335,
      "gpu_memory_mb": 2048,
      "link": "https://huggingface.co/intfloat/e5-large-v2"
    },
    {
      "id": "sentence-transformers/all-MiniLM-L6-v2",
      "name": "all-MiniLM-L6-v2",
      "team": "sentence-transformers",
      "task": "feature-extraction",
      "size_mb": 90,
      "parameters_m": 22,
      "gpu_memory_mb": 256,
      "link": "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"
    },
    {
      "id": "Qwen/Qwen3-Embedding-0.6B",
      "name": "Qwen3-Embedding-0.6B",
      "team": "Qwen",
      "task": "feature-extraction",
      "size_mb": 1200,
      "parameters_m": 600,
      "gpu_memory_mb": 1536,
      "link": "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B"
    },
    {
      "id": "jinaai/jina-embeddings-v3",
      "name": "jina-embeddings-v3",
      "team": "jinaai",
      "task": "feature-extraction",
      "size_mb": 1150,
      "parameters_m": 570,
      "gpu_memory_mb": 1536,
      "link": "https://huggingface.co/jinaai/jina-embeddings-v3"
    }
  ],
  "image-captioning": [
    {
      "id": "Salesforce/blip-image-captioning-base",
      "name": "blip-image-captioning-base",
      "team": "Salesforce",
      "task": "image-captioning",
      "architecture": "blip",
      "default_prompt": null,
      "size_mb": 990,
      "parameters_m": 224,
      "gpu_memory_mb": 1536,
      "link": "https://huggingface.co/Salesforce/blip-image-captioning-base"
    },
    {
      "id": "Salesforce/blip-image-captioning-large",
      "name": "blip-image-captioning-large",
      "team": "Salesforce",
      "task": "image-captioning",
      "architecture": "blip",
      "default_prompt": null,
      "size_mb": 1900,
      "parameters_m": 477,
      "gpu_memory_mb": 3072,
      "link": "https://huggingface.co/Salesforce/blip-image-captioning-large"
    },
    {
      "id": "Salesforce/blip2-opt-2.7b",
      "name": "blip2-opt-2.7b",
      "team": "Salesforce",
      "task": "image-captioning",
      "architecture": "blip2",
      "default_prompt": "Question: What is in this image? Answer:",
      "size_mb": 5400,
      "parameters_m": 2700,
      "gpu_memory_mb": 6144,
      "link": "https://huggingface.co/Salesforce/blip2-opt-2.7b"
    },
    {
      "id": "unsloth/llava-1.5-7b-hf-bnb-4bit",
      "name": "llava-1.5-7b-hf-bnb-4bit",
      "team": "unsloth",
      "task": "image-captioning",
      "architecture": "llava",
      "default_prompt": "USER: <image>\nDescribe this image in detail.\nASSISTANT:",
      "size_mb": 4200,
      "parameters_m": 7000,
      "gpu_memory_mb": 4096,
      "link": "https://huggingface.co/unsloth/llava-1.5-7b-hf-bnb-4bit",
      "platform_requirements": "Linux only (requires bitsandbytes)",
      "requires_quantization": true
    },
    {
      "id": "unsloth/llava-v1.6-mistral-7b-hf-bnb-4bit",
      "name": "llava-v1.6-mistral-7b-hf-bnb-4bit",
      "team": "unsloth",
      "task": "image-captioning",
      "architecture": "llava_next",
      "default_prompt": "USER: <image>\nDescribe this image in detail.\nASSISTANT:",
      "size_mb": 4500,
      "parameters_m": 7000,
      "gpu_memory_mb": 4096,
      "link": "https://huggingface.co/unsloth/llava-v1.6-mistral-7b-hf-bnb-4bit",
      "platform_requirements": "Linux only (requires bitsandbytes)",
      "requires_quantization": true
    }
  ],
  "image-ocr": [
    {
      "id": "PaddlePaddle/PaddleOCR-VL",
      "name": "PaddleOCR-VL",
      "team": "PaddlePaddle",
      "task": "image-ocr",
      "architecture": "paddleocr",
      "default_prompt": null,
      "size_mb": 2500,
      "parameters_m": 1000,
      "gpu_memory_mb": 3072,
      "link": "https://huggingface.co/PaddlePaddle/PaddleOCR-VL"
    },
    {
      "id": "opendatalab/MinerU2.5-2509-1.2B",
      "name": "MinerU2.5-2509-1.2B",
      "team": "opendatalab",
      "task": "image-ocr",
      "architecture": "mineru",
      "default_prompt": null,
      "size_mb": 2400,
      "parameters_m": 1200,
      "gpu_memory_mb": 3072,
      "link": "https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B",
      "platform_requirements": "Works with transformers >= 4.46.3 (use torch_dtype for versions < 4.56.0)"
    },
    {
      "id": "deepseek-ai/DeepSeek-OCR",
      "name": "DeepSeek-OCR",
      "team": "deepseek-ai",
      "task": "image-ocr",
      "architecture": "deepseek",
      "default_prompt": null,
      "size_mb": 6000,
      "parameters_m": 3000,
      "gpu_memory_mb": 8192,
      "link": "https://huggingface.co/deepseek-ai/DeepSeek-OCR",
      "platform_requirements": "Requires transformers==4.46.3, tokenizers==0.20.3. Optional: flash-attn==2.7.3 for GPU acceleration"
    },
    {
      "id": "ibm-granite/granite-docling-258M",
      "name": "granite-docling-258M",
      "team": "ibm-granite",
      "task": "image-ocr",
      "architecture": "granite-docling",
      "default_prompt": "Convert this page to markdown.",
      "size_mb": 520,
      "parameters_m": 258,
      "gpu_memory_mb": 2048,
      "link": "https://huggingface.co/ibm-granite/granite-docling-258M",
      "platform_requirements": "Requires transformers >= 4.45.0, docling_core. Optional: flash-attn for GPU acceleration"
    }
  ],
  "text-generation": [
    {
      "id": "Qwen/Qwen3-0.6B",
      "name": "Qwen3-0.6B",
      "team": "Qwen",
      "task": "text-generation",
      "architecture": "qwen2",
      "default_prompt": null,
      "size_mb": 1200,
      "parameters_m": 600,
      "gpu_memory_mb": 1536,
      "link": "https://huggingface.co/Qwen/Qwen3-0.6B"
    },
    {
      "id": "google/gemma-3-1b-it",
      "name": "gemma-3-1b-it",
      "team": "google",
      "task": "text-generation",
      "architecture": "gemma2",
      "default_prompt": null,
      "size_mb": 2100,
      "parameters_m": 1000,
      "gpu_memory_mb": 2560,
      "link": "https://huggingface.co/google/gemma-3-1b-it"
    }
  ],
  "automatic-speech-recognition": [
    {
      "id": "openai/whisper-large-v3",
      "name": "whisper-large-v3",
      "team": "openai",
      "task": "automatic-speech-recognition",
      "architecture": "whisper",
      "default_prompt": null,
      "size_mb": 6170,
      "parameters_m": 1550,
      "gpu_memory_mb": 6144,
      "link": "https://huggingface.co/openai/whisper-large-v3"
    },
    {
      "id": "openai/whisper-large-v3-turbo",
      "name": "whisper-large-v3-turbo",
      "team": "openai",
      "task": "automatic-speech-recognition",
      "architecture": "whisper",
      "default_prompt": null,
      "size_mb": 3090,
      "parameters_m": 809,
      "gpu_memory_mb": 4096,
      "link": "https://huggingface.co/openai/whisper-large-v3-turbo"
    },
    {
      "id": "pyannote/segmentation-3.0",
      "name": "segmentation-3.0",
      "team": "pyannote",
      "task": "automatic-speech-recognition",
      "architecture": "pyannote",
      "default_prompt": null,
      "size_mb": 150,
      "parameters_m": 50,
      "gpu_memory_mb": 1024,
      "link": "https://huggingface.co/pyannote/segmentation-3.0",
      "platform_requirements": "Requires pyannote.audio>=3.0 and HuggingFace access token. Used as dependency by speaker-diarization-3.1. Processes 10-second audio chunks at 16kHz."
    },
    {
      "id": "pyannote/speaker-diarization-3.1",
      "name": "speaker-diarization-3.1",
      "team": "pyannote",
      "task": "automatic-speech-recognition",
      "architecture": "pyannote",
      "default_prompt": null,
      "size_mb": 300,
      "parameters_m": 100,
      "gpu_memory_mb": 2048,
      "link": "https://huggingface.co/pyannote/speaker-diarization-3.1",
      "platform_requirements": "Requires pyannote.audio>=3.1 and HuggingFace access token. Must accept conditions for pyannote/segmentation-3.0 and pyannote/speaker-diarization-3.1"
    },
    {
      "id": "pyannote/embedding",
      "name": "embedding",
      "team": "pyannote",
      "task": "speaker-embedding",
      "architecture": "pyannote",
      "default_prompt": null,
      "size_mb": 50,
      "parameters_m": 3.56,
      "gpu_memory_mb": 512,
      "link": "https://huggingface.co/pyannote/embedding",
      "platform_requirements": "Requires pyannote.audio>=2.1 and HuggingFace access token. TDNN-based x-vector architecture with SincNet features. Achieves 2.8% EER on VoxCeleb 1."
    }
  ]
}
