{
  "models": [
    {
      "id": "deepseek-ai/DeepSeek-OCR",
      "label": "DeepSeek-OCR",
      "provider": "deepseek-ai",
      "tasks": ["image-captioning", "image-ocr"],
      "architecture": "deepseek",
      "default_prompt": "Describe this image in detail.",
      "supports_markdown": true,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "deepseek-ai/DeepSeek-OCR",
      "reference_url": "https://huggingface.co/deepseek-ai/DeepSeek-OCR",
      "size_mb": 6000,
      "parameters_m": 3000,
      "gpu_memory_mb": 8192,
      "platform_requirements": "Linux only (requires bitsandbytes). Uses 4-bit NF4 quantization by default. Optional: flash-attn for GPU acceleration",
      "python_env": "deepseek"
    },
    {
      "id": "pyannote/embedding",
      "label": "embedding",
      "provider": "pyannote",
      "tasks": ["speaker-embedding"],
      "architecture": "pyannote",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "pyannote/embedding",
      "reference_url": "https://huggingface.co/pyannote/embedding",
      "size_mb": 50,
      "parameters_m": 4,
      "gpu_memory_mb": 512,
      "platform_requirements": "Requires pyannote.audio>=2.1 and HuggingFace access token. TDNN-based x-vector architecture with SincNet features. Achieves 2.8% EER on VoxCeleb 1. Actual: 3.56M params.",
      "python_env": "whisper"
    },
    {
      "id": "google/gemma-3-1b-it",
      "label": "gemma-3-1b-it",
      "provider": "google",
      "tasks": ["text-generation"],
      "architecture": "gemma2",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "google/gemma-3-1b-it",
      "reference_url": "https://huggingface.co/google/gemma-3-1b-it",
      "size_mb": 2100,
      "parameters_m": 1000,
      "gpu_memory_mb": 2560,
      "platform_requirements": null,
      "python_env": "transformers"
    },
    {
      "id": "jinaai/jina-embeddings-v3",
      "label": "jina-embeddings-v3",
      "provider": "jinaai",
      "tasks": ["feature-extraction"],
      "architecture": null,
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "jinaai/jina-embeddings-v3",
      "reference_url": "https://huggingface.co/jinaai/jina-embeddings-v3",
      "size_mb": 1150,
      "parameters_m": 570,
      "gpu_memory_mb": 1536,
      "dimensions": 1024,
      "platform_requirements": null,
      "python_env": "transformers"
    },
    {
      "id": "jinaai/jina-vlm",
      "label": "jina-vlm",
      "provider": "jinaai",
      "tasks": ["image-captioning"],
      "architecture": "jina-vlm",
      "default_prompt": "Describe this image",
      "supports_markdown": true,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "jinaai/jina-vlm",
      "reference_url": "https://huggingface.co/jinaai/jina-vlm",
      "size_mb": 4800,
      "parameters_m": 2400,
      "gpu_memory_mb": 5120,
      "platform_requirements": "Requires trust_remote_code=True. Uses float16 or bfloat16 precision. Optional: flash-attn for GPU acceleration.",
      "python_env": "transformers"
    },
    {
      "id": "vikhyatk/moondream2",
      "label": "moondream2",
      "provider": "vikhyatk",
      "tasks": ["image-captioning"],
      "architecture": "moondream",
      "default_prompt": "Describe this image in detail.",
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "vikhyatk/moondream2",
      "reference_url": "https://huggingface.co/vikhyatk/moondream2",
      "size_mb": 4000,
      "parameters_m": 2000,
      "gpu_memory_mb": 4096,
      "platform_requirements": "Requires trust_remote_code=True. Uses BF16 precision.",
      "python_env": "transformers"
    },
    {
      "id": "opendatalab/MinerU2.5-2509-1.2B",
      "label": "MinerU2.5-2509-1.2B",
      "provider": "opendatalab",
      "tasks": ["image-ocr"],
      "architecture": "mineru",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "opendatalab/MinerU2.5-2509-1.2B",
      "reference_url": "https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B",
      "size_mb": 2400,
      "parameters_m": 1200,
      "gpu_memory_mb": 3072,
      "platform_requirements": "Works with transformers >= 4.46.3 (use torch_dtype for versions < 4.56.0)",
      "python_env": "transformers"
    },
    {
      "id": "Qwen/Qwen3-0.6B",
      "label": "Qwen3-0.6B",
      "provider": "Qwen",
      "tasks": ["text-generation"],
      "architecture": "qwen2",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "Qwen/Qwen3-0.6B",
      "reference_url": "https://huggingface.co/Qwen/Qwen3-0.6B",
      "size_mb": 1200,
      "parameters_m": 600,
      "gpu_memory_mb": 1536,
      "platform_requirements": null,
      "python_env": "transformers"
    },
    {
      "id": "Qwen/Qwen3-Embedding-0.6B",
      "label": "Qwen3-Embedding-0.6B",
      "provider": "Qwen",
      "tasks": ["feature-extraction"],
      "architecture": null,
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "Qwen/Qwen3-Embedding-0.6B",
      "reference_url": "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B",
      "size_mb": 1200,
      "parameters_m": 600,
      "gpu_memory_mb": 1536,
      "dimensions": 1024,
      "platform_requirements": null,
      "python_env": "transformers"
    },
    {
      "id": "pyannote/segmentation-3.0",
      "label": "segmentation-3.0",
      "provider": "pyannote",
      "tasks": ["automatic-speech-recognition"],
      "architecture": "pyannote",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "pyannote/segmentation-3.0",
      "reference_url": "https://huggingface.co/pyannote/segmentation-3.0",
      "size_mb": 150,
      "parameters_m": 50,
      "gpu_memory_mb": 1024,
      "platform_requirements": "Requires pyannote.audio>=3.0 and HuggingFace access token. Used as dependency by speaker-diarization-3.1. Processes 10-second audio chunks at 16kHz.",
      "python_env": "whisper"
    },
    {
      "id": "pyannote/speaker-diarization-3.1",
      "label": "speaker-diarization-3.1",
      "provider": "pyannote",
      "tasks": ["automatic-speech-recognition"],
      "architecture": "pyannote",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "pyannote/speaker-diarization-3.1",
      "reference_url": "https://huggingface.co/pyannote/speaker-diarization-3.1",
      "size_mb": 300,
      "parameters_m": 100,
      "gpu_memory_mb": 2048,
      "platform_requirements": "Requires pyannote.audio>=3.1 and HuggingFace access token. Must accept conditions for pyannote/segmentation-3.0 and pyannote/speaker-diarization-3.1",
      "python_env": "whisper"
    },
    {
      "id": "openai/whisper-large-v3",
      "label": "whisper-large-v3",
      "provider": "openai",
      "tasks": ["automatic-speech-recognition"],
      "architecture": "whisper",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "openai/whisper-large-v3",
      "reference_url": "https://huggingface.co/openai/whisper-large-v3",
      "size_mb": 6170,
      "parameters_m": 1550,
      "gpu_memory_mb": 6144,
      "platform_requirements": null,
      "python_env": "whisper"
    },
    {
      "id": "openai/whisper-large-v3-turbo",
      "label": "whisper-large-v3-turbo",
      "provider": "openai",
      "tasks": ["automatic-speech-recognition"],
      "architecture": "whisper",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "openai/whisper-large-v3-turbo",
      "reference_url": "https://huggingface.co/openai/whisper-large-v3-turbo",
      "size_mb": 3090,
      "parameters_m": 809,
      "gpu_memory_mb": 4096,
      "platform_requirements": null,
      "python_env": "whisper"
    },
    {
      "id": "tencent/HunyuanOCR",
      "label": "HunyuanOCR",
      "provider": "tencent",
      "tasks": ["image-ocr"],
      "architecture": "hunyuan-ocr",
      "default_prompt": null,
      "supports_markdown": true,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "tencent/HunyuanOCR",
      "reference_url": "https://huggingface.co/tencent/HunyuanOCR",
      "size_mb": 2000,
      "parameters_m": 1000,
      "gpu_memory_mb": 10240,
      "platform_requirements": "Requires 10GB+ VRAM (vision transformer needs ~7GB during inference). Requires transformers from commit 82a06db (not yet in stable release): pip install git+https://github.com/huggingface/transformers@82a06db03535c49aa987719ed0746a76093b1ec4. Uses bfloat16. Supports multilingual OCR, document parsing, tables (HTML), formulas (LaTeX), and flowcharts (Mermaid).",
      "python_env": "hunyuan"
    },
    {
      "id": "PaddlePaddle/PaddleOCR-VL",
      "label": "PaddleOCR-VL",
      "provider": "PaddlePaddle",
      "tasks": ["image-ocr"],
      "architecture": "paddleocr",
      "default_prompt": null,
      "supports_markdown": true,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "PaddlePaddle/PaddleOCR-VL",
      "reference_url": "https://huggingface.co/PaddlePaddle/PaddleOCR-VL",
      "size_mb": 2000,
      "parameters_m": 900,
      "gpu_memory_mb": 3500,
      "platform_requirements": "Uses transformers backend with flash_attention_2 for 12x memory reduction (~3.3GB vs ~40GB). Optional: pip install flash-attn for best performance. Supports 109 languages, tables, formulas, charts, and markdown output.",
      "python_env": "transformers"
    },
    {
      "id": "FunAudioLLM/CosyVoice2-0.5B",
      "label": "CosyVoice2-0.5B",
      "provider": "FunAudioLLM",
      "tasks": ["text-to-speech"],
      "architecture": "cosyvoice",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "FunAudioLLM/CosyVoice2-0.5B",
      "reference_url": "https://huggingface.co/FunAudioLLM/CosyVoice2-0.5B",
      "size_mb": 2000,
      "parameters_m": 500,
      "gpu_memory_mb": 8192,
      "platform_requirements": "Requires Python 3.10. Supports 9 languages and 18+ Chinese dialects. Zero-shot voice cloning, cross-lingual synthesis, and instruction-based control. ~150ms streaming latency.",
      "python_env": "cosyvoice"
    },
    {
      "id": "FunAudioLLM/Fun-CosyVoice3-0.5B",
      "label": "Fun-CosyVoice3-0.5B",
      "provider": "FunAudioLLM",
      "tasks": ["text-to-speech"],
      "architecture": "cosyvoice",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "FunAudioLLM/Fun-CosyVoice3-0.5B-2512",
      "reference_url": "https://huggingface.co/FunAudioLLM/Fun-CosyVoice3-0.5B-2512",
      "size_mb": 2000,
      "parameters_m": 500,
      "gpu_memory_mb": 8192,
      "platform_requirements": "Requires Python 3.10. Latest CosyVoice 3.0 model (Dec 2025). Supports 9 languages + 18 Chinese dialects. Best-in-class zero-shot voice cloning with ~150ms streaming latency.",
      "python_env": "cosyvoice"
    },
    {
      "id": "FunAudioLLM/CosyVoice-300M",
      "label": "CosyVoice-300M",
      "provider": "FunAudioLLM",
      "tasks": ["text-to-speech"],
      "architecture": "cosyvoice",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "FunAudioLLM/CosyVoice-300M",
      "reference_url": "https://huggingface.co/FunAudioLLM/CosyVoice-300M",
      "size_mb": 1200,
      "parameters_m": 300,
      "gpu_memory_mb": 4096,
      "platform_requirements": "Requires Python 3.10. Lightweight model for faster inference. Supports zero-shot and cross-lingual synthesis.",
      "python_env": "cosyvoice"
    },
    {
      "id": "FunAudioLLM/CosyVoice-300M-SFT",
      "label": "CosyVoice-300M-SFT",
      "provider": "FunAudioLLM",
      "tasks": ["text-to-speech"],
      "architecture": "cosyvoice",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "FunAudioLLM/CosyVoice-300M-SFT",
      "reference_url": "https://huggingface.co/FunAudioLLM/CosyVoice-300M-SFT",
      "size_mb": 1200,
      "parameters_m": 300,
      "gpu_memory_mb": 4096,
      "platform_requirements": "Requires Python 3.10. Pre-trained speaker voices (SFT mode). No reference audio needed.",
      "python_env": "cosyvoice"
    },
    {
      "id": "FunAudioLLM/CosyVoice-300M-Instruct",
      "label": "CosyVoice-300M-Instruct",
      "provider": "FunAudioLLM",
      "tasks": ["text-to-speech"],
      "architecture": "cosyvoice",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "FunAudioLLM/CosyVoice-300M-Instruct",
      "reference_url": "https://huggingface.co/FunAudioLLM/CosyVoice-300M-Instruct",
      "size_mb": 1200,
      "parameters_m": 300,
      "gpu_memory_mb": 4096,
      "platform_requirements": "Requires Python 3.10. Natural language instruction control for emotions, speed, dialect, etc.",
      "python_env": "cosyvoice"
    }
  ]
}
