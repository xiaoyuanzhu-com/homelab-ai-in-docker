{
  "models": [
    {
      "id": "sentence-transformers/all-MiniLM-L6-v2",
      "label": "all-MiniLM-L6-v2",
      "provider": "sentence-transformers",
      "tasks": ["feature-extraction"],
      "architecture": null,
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "sentence-transformers/all-MiniLM-L6-v2",
      "reference_url": "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2",
      "size_mb": 90,
      "parameters_m": 22,
      "gpu_memory_mb": 256,
      "dimensions": 384,
      "platform_requirements": null
    },
    {
      "id": "BAAI/bge-large-en-v1.5",
      "label": "bge-large-en-v1.5",
      "provider": "BAAI",
      "tasks": ["feature-extraction"],
      "architecture": null,
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "BAAI/bge-large-en-v1.5",
      "reference_url": "https://huggingface.co/BAAI/bge-large-en-v1.5",
      "size_mb": 1340,
      "parameters_m": 335,
      "gpu_memory_mb": 2048,
      "dimensions": 1024,
      "platform_requirements": null
    },
    {
      "id": "deepseek-ai/DeepSeek-OCR",
      "label": "DeepSeek-OCR",
      "provider": "deepseek-ai",
      "tasks": ["image-captioning", "image-ocr"],
      "architecture": "deepseek",
      "default_prompt": "Describe this image in detail.",
      "supports_markdown": true,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "deepseek-ai/DeepSeek-OCR",
      "reference_url": "https://huggingface.co/deepseek-ai/DeepSeek-OCR",
      "size_mb": 6000,
      "parameters_m": 3000,
      "gpu_memory_mb": 8192,
      "platform_requirements": "Linux only (requires bitsandbytes). Uses 4-bit NF4 quantization by default. Optional: flash-attn for GPU acceleration",
      "python_env": "deepseek-ocr"
    },
    {
      "id": "intfloat/e5-large-v2",
      "label": "E5-large-v2",
      "provider": "intfloat",
      "tasks": ["feature-extraction"],
      "architecture": null,
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "intfloat/e5-large-v2",
      "reference_url": "https://huggingface.co/intfloat/e5-large-v2",
      "size_mb": 1340,
      "parameters_m": 335,
      "gpu_memory_mb": 2048,
      "dimensions": 1024,
      "platform_requirements": null
    },
    {
      "id": "pyannote/embedding",
      "label": "embedding",
      "provider": "pyannote",
      "tasks": ["speaker-embedding"],
      "architecture": "pyannote",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "pyannote/embedding",
      "reference_url": "https://huggingface.co/pyannote/embedding",
      "size_mb": 50,
      "parameters_m": 4,
      "gpu_memory_mb": 512,
      "platform_requirements": "Requires pyannote.audio>=2.1 and HuggingFace access token. TDNN-based x-vector architecture with SincNet features. Achieves 2.8% EER on VoxCeleb 1. Actual: 3.56M params."
    },
    {
      "id": "google/gemma-3-1b-it",
      "label": "gemma-3-1b-it",
      "provider": "google",
      "tasks": ["text-generation"],
      "architecture": "gemma2",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "google/gemma-3-1b-it",
      "reference_url": "https://huggingface.co/google/gemma-3-1b-it",
      "size_mb": 2100,
      "parameters_m": 1000,
      "gpu_memory_mb": 2560,
      "platform_requirements": null
    },
    {
      "id": "ibm-granite/granite-docling-258M",
      "label": "granite-docling-258M",
      "provider": "ibm-granite",
      "tasks": ["image-ocr"],
      "architecture": "granite-docling",
      "default_prompt": "Convert this page to markdown.",
      "supports_markdown": true,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "ibm-granite/granite-docling-258M",
      "reference_url": "https://huggingface.co/ibm-granite/granite-docling-258M",
      "size_mb": 520,
      "parameters_m": 258,
      "gpu_memory_mb": 2048,
      "platform_requirements": "Requires transformers >= 4.45.0, docling_core. Optional: flash-attn for GPU acceleration"
    },
    {
      "id": "Alibaba-NLP/gte-large-en-v1.5",
      "label": "gte-large-en-v1.5",
      "provider": "Alibaba-NLP",
      "tasks": ["feature-extraction"],
      "architecture": null,
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "Alibaba-NLP/gte-large-en-v1.5",
      "reference_url": "https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5",
      "size_mb": 1340,
      "parameters_m": 335,
      "gpu_memory_mb": 2048,
      "dimensions": 1024,
      "platform_requirements": null
    },
    {
      "id": "jinaai/jina-embeddings-v3",
      "label": "jina-embeddings-v3",
      "provider": "jinaai",
      "tasks": ["feature-extraction"],
      "architecture": null,
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "jinaai/jina-embeddings-v3",
      "reference_url": "https://huggingface.co/jinaai/jina-embeddings-v3",
      "size_mb": 1150,
      "parameters_m": 570,
      "gpu_memory_mb": 1536,
      "dimensions": 1024,
      "platform_requirements": null
    },
    {
      "id": "jinaai/jina-vlm",
      "label": "jina-vlm",
      "provider": "jinaai",
      "tasks": ["image-captioning"],
      "architecture": "jina-vlm",
      "default_prompt": "Describe this image",
      "supports_markdown": true,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "jinaai/jina-vlm",
      "reference_url": "https://huggingface.co/jinaai/jina-vlm",
      "size_mb": 4800,
      "parameters_m": 2400,
      "gpu_memory_mb": 5120,
      "platform_requirements": "Requires trust_remote_code=True. Uses float16 or bfloat16 precision. Optional: flash-attn for GPU acceleration."
    },
    {
      "id": "vikhyatk/moondream2",
      "label": "moondream2",
      "provider": "vikhyatk",
      "tasks": ["image-captioning"],
      "architecture": "moondream",
      "default_prompt": "Describe this image in detail.",
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "vikhyatk/moondream2",
      "reference_url": "https://huggingface.co/vikhyatk/moondream2",
      "size_mb": 4000,
      "parameters_m": 2000,
      "gpu_memory_mb": 4096,
      "platform_requirements": "Requires trust_remote_code=True. Uses BF16 precision."
    },
    {
      "id": "opendatalab/MinerU2.5-2509-1.2B",
      "label": "MinerU2.5-2509-1.2B",
      "provider": "opendatalab",
      "tasks": ["image-ocr"],
      "architecture": "mineru",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "opendatalab/MinerU2.5-2509-1.2B",
      "reference_url": "https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B",
      "size_mb": 2400,
      "parameters_m": 1200,
      "gpu_memory_mb": 3072,
      "platform_requirements": "Works with transformers >= 4.46.3 (use torch_dtype for versions < 4.56.0)"
    },
    {
      "id": "Qwen/Qwen3-0.6B",
      "label": "Qwen3-0.6B",
      "provider": "Qwen",
      "tasks": ["text-generation"],
      "architecture": "qwen2",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "Qwen/Qwen3-0.6B",
      "reference_url": "https://huggingface.co/Qwen/Qwen3-0.6B",
      "size_mb": 1200,
      "parameters_m": 600,
      "gpu_memory_mb": 1536,
      "platform_requirements": null
    },
    {
      "id": "Qwen/Qwen3-Embedding-0.6B",
      "label": "Qwen3-Embedding-0.6B",
      "provider": "Qwen",
      "tasks": ["feature-extraction"],
      "architecture": null,
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "Qwen/Qwen3-Embedding-0.6B",
      "reference_url": "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B",
      "size_mb": 1200,
      "parameters_m": 600,
      "gpu_memory_mb": 1536,
      "dimensions": 1024,
      "platform_requirements": null
    },
    {
      "id": "pyannote/segmentation-3.0",
      "label": "segmentation-3.0",
      "provider": "pyannote",
      "tasks": ["automatic-speech-recognition"],
      "architecture": "pyannote",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "pyannote/segmentation-3.0",
      "reference_url": "https://huggingface.co/pyannote/segmentation-3.0",
      "size_mb": 150,
      "parameters_m": 50,
      "gpu_memory_mb": 1024,
      "platform_requirements": "Requires pyannote.audio>=3.0 and HuggingFace access token. Used as dependency by speaker-diarization-3.1. Processes 10-second audio chunks at 16kHz."
    },
    {
      "id": "pyannote/speaker-diarization-3.1",
      "label": "speaker-diarization-3.1",
      "provider": "pyannote",
      "tasks": ["automatic-speech-recognition"],
      "architecture": "pyannote",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "pyannote/speaker-diarization-3.1",
      "reference_url": "https://huggingface.co/pyannote/speaker-diarization-3.1",
      "size_mb": 300,
      "parameters_m": 100,
      "gpu_memory_mb": 2048,
      "platform_requirements": "Requires pyannote.audio>=3.1 and HuggingFace access token. Must accept conditions for pyannote/segmentation-3.0 and pyannote/speaker-diarization-3.1"
    },
    {
      "id": "openai/whisper-large-v3",
      "label": "whisper-large-v3",
      "provider": "openai",
      "tasks": ["automatic-speech-recognition"],
      "architecture": "whisper",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "openai/whisper-large-v3",
      "reference_url": "https://huggingface.co/openai/whisper-large-v3",
      "size_mb": 6170,
      "parameters_m": 1550,
      "gpu_memory_mb": 6144,
      "platform_requirements": null
    },
    {
      "id": "openai/whisper-large-v3-turbo",
      "label": "whisper-large-v3-turbo",
      "provider": "openai",
      "tasks": ["automatic-speech-recognition"],
      "architecture": "whisper",
      "default_prompt": null,
      "supports_markdown": false,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "openai/whisper-large-v3-turbo",
      "reference_url": "https://huggingface.co/openai/whisper-large-v3-turbo",
      "size_mb": 3090,
      "parameters_m": 809,
      "gpu_memory_mb": 4096,
      "platform_requirements": null
    },
    {
      "id": "tencent/HunyuanOCR",
      "label": "HunyuanOCR",
      "provider": "tencent",
      "tasks": ["image-ocr"],
      "architecture": "hunyuan-ocr",
      "default_prompt": null,
      "supports_markdown": true,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "tencent/HunyuanOCR",
      "reference_url": "https://huggingface.co/tencent/HunyuanOCR",
      "size_mb": 2000,
      "parameters_m": 1000,
      "gpu_memory_mb": 10240,
      "platform_requirements": "Requires 10GB+ VRAM (vision transformer needs ~7GB during inference). Requires transformers from commit 82a06db (not yet in stable release): pip install git+https://github.com/huggingface/transformers@82a06db03535c49aa987719ed0746a76093b1ec4. Uses bfloat16. Supports multilingual OCR, document parsing, tables (HTML), formulas (LaTeX), and flowcharts (Mermaid)."
    },
    {
      "id": "PaddlePaddle/PaddleOCR-VL",
      "label": "PaddleOCR-VL",
      "provider": "PaddlePaddle",
      "tasks": ["image-ocr"],
      "architecture": "paddleocr",
      "default_prompt": null,
      "supports_markdown": true,
      "requires_quantization": false,
      "requires_download": true,
      "hf_model": "PaddlePaddle/PaddleOCR-VL",
      "reference_url": "https://huggingface.co/PaddlePaddle/PaddleOCR-VL",
      "size_mb": 2000,
      "parameters_m": 1000,
      "gpu_memory_mb": 4096,
      "platform_requirements": "Requires PaddlePaddle 3.2.1+, paddleocr[doc-parser], and safetensors with Paddle support (pip install https://paddle-whl.bj.bcebos.com/nightly/cu126/safetensors/safetensors-0.6.2.dev0-cp38-abi3-linux_x86_64.whl). Uses bfloat16. Supports 109 languages, tables, formulas, charts, and markdown output."
    }
  ]
}
