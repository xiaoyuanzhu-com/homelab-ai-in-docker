[project]
name = "hunyuan-worker"
version = "0.1.0"
description = "HunyuanOCR worker environment (requires unreleased transformers features)"
requires-python = ">=3.13"
dependencies = [
    # Core ML stack
    "torch==2.8.0",
    "torchvision==0.23.0",
    # Transformers from git (unreleased features for HunyuanOCR)
    "transformers @ git+https://github.com/huggingface/transformers.git",
    "accelerate>=0.20.0",
    "safetensors>=0.4.0",
    # Image handling
    "pillow>=10.0.0",
    "pillow-heif>=1.0.0",
    "opencv-python-headless>=4.8.0",
    # Utilities
    "einops>=0.7.0",
    # Worker HTTP server
    "fastapi>=0.115.0",
    "uvicorn>=0.32.0",
    # CUDA runtime libs (Linux only)
    "nvidia-cuda-runtime-cu12>=12.6,<12.7; platform_system=='Linux'",
    "nvidia-cuda-nvrtc-cu12>=12.6,<12.7; platform_system=='Linux'",
    "nvidia-cuda-cupti-cu12>=12.6,<12.7; platform_system=='Linux'",
    "nvidia-cublas-cu12>=12.6,<12.7; platform_system=='Linux'",
    "nvidia-cufft-cu12>=11.3,<11.4; platform_system=='Linux'",
    "nvidia-nvjitlink-cu12>=12.6,<12.7; platform_system=='Linux'",
    "nvidia-cudnn-cu12==9.10.2.21; platform_system=='Linux'",
]

# Note: flash-attn requires specific pre-built wheels for each Python/CUDA/torch combo
# and will be installed separately if needed

[tool.uv]
package = false

# PyTorch CUDA 12.6 index
[[tool.uv.index]]
name = "pytorch-cu126"
url = "https://download.pytorch.org/whl/cu126"
explicit = true

[tool.uv.sources]
torch = { index = "pytorch-cu126" }
torchvision = { index = "pytorch-cu126" }
