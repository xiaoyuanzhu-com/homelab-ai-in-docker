[project]
name = "cosyvoice-worker"
version = "0.1.0"
description = "CosyVoice text-to-speech worker environment"
requires-python = ">=3.10,<3.11"
dependencies = [
    # NOTE: torch/torchaudio CUDA 12.4 versions are installed via post_install.sh
    # We let PyPI torch be pulled in by dependencies (openai-whisper, etc.),
    # then post_install.sh upgrades to cu124 version with cuDNN 9.x
    # CosyVoice core dependencies (CosyVoice repo is cloned separately and added to PYTHONPATH)
    "conformer==0.3.2",
    "diffusers==0.29.0",
    "hydra-core==1.3.2",
    "HyperPyYAML==1.2.2",
    "inflect==7.3.1",
    "librosa==0.10.2",
    "lightning==2.2.4",
    "matplotlib==3.7.5",
    "modelscope>=1.20.0",
    "networkx==3.1",
    "numpy==1.26.4",
    "omegaconf==2.3.0",
    "onnx==1.16.0",
    "openai-whisper==20231117",
    "protobuf==4.25.0",
    "pydantic>=2.7.0",
    "pyworld==0.3.4",
    "rich==13.7.1",
    "soundfile==0.12.1",
    "tensorboard==2.14.0",
    "transformers>=4.40.0",
    "x-transformers",
    "wetext==0.0.4",
    "wget==3.2",
    "gdown==5.1.0",
    "pyarrow>=14.0.0",
    # HuggingFace for model downloads
    "huggingface_hub>=0.20.0",
    # Worker HTTP server
    "fastapi>=0.115.0",
    "uvicorn>=0.32.0",
    # Linux-only dependencies
    # onnxruntime-gpu 1.19+ requires CUDA 12.x and cuDNN 9.x
    "onnxruntime-gpu>=1.19.0; platform_system=='Linux'",
    "onnxruntime>=1.19.0; platform_system!='Linux'",
    # CUDA runtime libs (Linux only) - aligned with PyTorch cu121
    "nvidia-cuda-runtime-cu12>=12.1,<13; platform_system=='Linux'",
    "nvidia-cuda-nvrtc-cu12>=12.1,<13; platform_system=='Linux'",
    "nvidia-cublas-cu12>=12.1,<13; platform_system=='Linux'",
    "nvidia-cufft-cu12>=11.0,<12; platform_system=='Linux'",
    "nvidia-cudnn-cu12>=9.0,<10; platform_system=='Linux'",
]

[tool.uv]
package = false
